# Wispr Flow Clone â€“ Voice to Text Desktop App

A cross-platform voice-to-text desktop application built using **Tauri**, **React**, and **Deepgram**.  
This project focuses on implementing the core voice-to-text workflow similar to Wispr Flow, prioritizing functionality and clean architecture over UI styling.

---

## ğŸ¯ Project Objective

The goal of this assignment is to demonstrate:
- Desktop application development using Tauri
- Microphone audio capture
- AI-powered speech-to-text integration
- Clean separation of concerns
- Practical problem-solving and integration skills

---

## ğŸ›  Tech Stack

- **Frontend**: React + Vite
- **Desktop Framework**: Tauri
- **Speech-to-Text**: Deepgram API (REST)
- **Language**: JavaScript
- **Platforms**: Windows / macOS / Linux

---

## âœ¨ Features Implemented

- Push-to-talk voice input
- Microphone permission handling
- Audio recording using MediaRecorder
- Speech-to-text transcription via Deepgram
- Display of transcribed text in UI
- Works in both browser and Tauri desktop app

---

## ğŸ— Architecture Overview

The application is structured with a clear separation of concerns:

src/
â”œâ”€â”€ components/
â”‚ â”œâ”€â”€ Recorder.jsx # Handles user interaction & recording control
â”‚ â””â”€â”€ Transcript.jsx # Displays transcription output
â”‚
â”œâ”€â”€ services/
â”‚ â”œâ”€â”€ audioService.js # Microphone access & audio recording
â”‚ â””â”€â”€ deepgramService.js # Deepgram REST API integration
â”‚
â”œâ”€â”€ App.jsx # Application state & orchestration
â””â”€â”€ main.jsx # Entry point

#Setup Instructions
1ï¸âƒ£ Clone the repository
git clone https://github.com/Renugasri-1/wispr-flow-clone
cd wispr-flow-clone

2ï¸âƒ£ Install dependencies
npm install

3ï¸âƒ£ Configure environment variables
Create a .env file in the project root:
VITE_DEEPGRAM_API_KEY=your_deepgram_api_key

âš ï¸ Do not commit .env. Use .env.example as reference.

4ï¸âƒ£ Run in browser (development)
npm run dev
Open:
http://localhost:5174

5ï¸âƒ£ Run as desktop application
npx tauri dev

ğŸ¤ How It Works
User holds the â€œHold to Talkâ€ button
Audio is recorded using the browser MediaRecorder API
On release, the audio is sent to Deepgram via REST API
Deepgram processes the audio and returns transcription
Transcribed text is displayed in the application

âš ï¸ Known Limitations
Uses REST-based transcription 
No advanced UI styling or animations
No offline transcription support
Minimal error handling 

ğŸ“½ Demo Video
A demo video showcasing:
Desktop app launch
Voice recording
Speech-to-text transcription

ğŸ‘‰ Demo video link:




